[Unit]
Description=HiveCoder-7B LLM Server (llama.cpp)
Documentation=https://github.com/ggerganov/llama.cpp
After=network.target

[Service]
Type=simple
User=hashcat
Group=hashcat
WorkingDirectory=/var/mnt/build/MCP/hive-mind/learning-pipeline

# Use wrapper script for proper environment setup
ExecStart=/bin/bash /var/mnt/build/MCP/hive-mind/scripts/start-hivecoder.sh

# Auto-restart on failure
Restart=on-failure
RestartSec=10

# Resource limits
LimitNOFILE=65536
LimitMEMLOCK=infinity

# Security hardening (relaxed for GPU access)
NoNewPrivileges=false

[Install]
WantedBy=multi-user.target

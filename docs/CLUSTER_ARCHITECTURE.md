# ğŸ Hive-Mind: Redis Cluster + Sentinel Architecture

## Overview

**Design**: Distributed Redis Cluster with high availability monitoring

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ BEAST (192.168.1.100)            â”‚
â”‚ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€   â”‚
â”‚                                  â”‚
â”‚ Redis Cluster (6 nodes)          â”‚
â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚ â”‚ Masters (data sharding)     â”‚  â”‚
â”‚ â”‚ â”œâ”€ 7000: slots 0-5460       â”‚  â”‚
â”‚ â”‚ â”œâ”€ 7001: slots 5461-10922   â”‚  â”‚
â”‚ â”‚ â””â”€ 7002: slots 10923-16383  â”‚  â”‚
â”‚ â”‚                             â”‚  â”‚
â”‚ â”‚ Replicas (redundancy)       â”‚  â”‚
â”‚ â”‚ â”œâ”€ 7003 â†’ replicates 7000   â”‚  â”‚
â”‚ â”‚ â”œâ”€ 7004 â†’ replicates 7001   â”‚  â”‚
â”‚ â”‚ â””â”€ 7005 â†’ replicates 7002   â”‚  â”‚
â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚                                  â”‚
â”‚ Storage: /mnt/build/redis-clusterâ”‚
â”‚ Persistence: AOF + RDB           â”‚
â”‚ Memory: 2GB per node (12GB total)â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
          â†•
    1Gbps Network
          â†•
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ NAS (192.168.1.7)                â”‚
â”‚ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€   â”‚
â”‚                                  â”‚
â”‚ Redis Sentinel (3 instances)     â”‚
â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚ â”‚ Monitors (quorum-based)     â”‚  â”‚
â”‚ â”‚ â”œâ”€ 26379 â†’ monitors all     â”‚  â”‚
â”‚ â”‚ â”œâ”€ 26380 â†’ monitors all     â”‚  â”‚
â”‚ â”‚ â””â”€ 26381 â†’ monitors all     â”‚  â”‚
â”‚ â”‚                             â”‚  â”‚
â”‚ â”‚ Responsibilities:           â”‚  â”‚
â”‚ â”‚ â€¢ Health monitoring         â”‚  â”‚
â”‚ â”‚ â€¢ Automatic failover        â”‚  â”‚
â”‚ â”‚ â€¢ Config updates            â”‚  â”‚
â”‚ â”‚ â€¢ Notification alerts       â”‚  â”‚
â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚                                  â”‚
â”‚ Storage (NFS)                    â”‚
â”‚ â””â”€ /moar/ai/redis-backups        â”‚
â”‚    â”œâ”€ Hourly snapshots           â”‚
â”‚    â”œâ”€ Daily snapshots            â”‚
â”‚    â””â”€ 9.2TB available            â”‚
â”‚                                  â”‚
â”‚ Memory: ~150MB for Sentinels     â”‚
â”‚ CPU: Intel Atom C3338 (2 cores)  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## Why This Architecture?

### Redis Cluster (BEAST)
**Purpose**: Fast distributed data storage with automatic sharding

**Benefits**:
- âœ… **Horizontal scaling**: Data sharded across 3 masters
- âœ… **High availability**: Each master has a replica
- âœ… **Performance**: In-memory operations, ~277GB storage
- âœ… **Persistence**: AOF + RDB for durability
- âœ… **Auto-sharding**: Keys distributed by hash slot

**Trade-offs**:
- âš ï¸ Single point of failure: All on BEAST
- âš ï¸ Manual failover required without Sentinel

### Redis Sentinel (NAS)
**Purpose**: Monitoring and automatic failover

**Benefits**:
- âœ… **Auto-failover**: Promotes replica if master fails
- âœ… **Quorum-based**: 3 sentinels, need 2 to agree
- âœ… **Lightweight**: ~50MB RAM per sentinel
- âœ… **Separate failure domain**: NAS independent of BEAST
- âœ… **Config management**: Updates clients on topology changes

**Trade-offs**:
- âš ï¸ NAS has old OS (requires static binary)
- âš ï¸ Limited RAM (1.8GB, but 150MB is fine)

### Storage Layer (NAS)
**Purpose**: Persistent backups and disaster recovery

**Benefits**:
- âœ… **9.2TB storage**: Massive backup capacity
- âœ… **24/7 uptime**: NAS always on
- âœ… **RAID redundancy**: Data protected
- âœ… **Network accessible**: Any node can backup

## Data Flow

### Normal Operations
```
Client (MCP Server)
    â†“
Redis Cluster (BEAST)
    â”œâ”€ Hash key â†’ determine slot
    â”œâ”€ Route to correct master
    â”œâ”€ Replicate to replica
    â””â”€ Return result

Sentinel (NAS) [background]
    â”œâ”€ Ping masters every 1s
    â”œâ”€ Check replica replication lag
    â””â”€ Monitor cluster health
```

### Failover Scenario
```
Master 7000 crashes
    â†“
Sentinels detect (1s ping timeout)
    â†“
Quorum vote (2/3 sentinels agree)
    â†“
Promote replica 7003 to master
    â†“
Update cluster topology
    â†“
Notify clients of new master
    â†“
Service continues (< 5s downtime)
```

### Backup Flow
```
Hourly cron job (BEAST)
    â†“
BGSAVE on each master
    â†“
Copy RDB files via NFS
    â†“
Store on NAS: /moar/ai/redis-backups/
    â†“
Retain: 24h/7d/4w
```

## Configuration

### Cluster Nodes (BEAST)
```yaml
Ports: 7000-7005
Network: host mode (Docker)
Persistence:
  - AOF: appendfsync everysec
  - RDB: save 900 1 / 300 10 / 60 10000
  - Dir: /mnt/build/redis-cluster/node-{port}/data
Memory:
  - maxmemory: 2gb per node
  - maxmemory-policy: allkeys-lru
Security:
  - requirepass: (shared password)
  - masterauth: (for replication)
Cluster:
  - cluster-enabled: yes
  - cluster-node-timeout: 5000
```

### Sentinel Nodes (NAS)
```yaml
Ports: 26379-26381
Monitor:
  - master-7000 (192.168.1.100:7000)
  - master-7001 (192.168.1.100:7001)
  - master-7002 (192.168.1.100:7002)
Quorum: 2 (out of 3 sentinels)
Down-after: 5000ms
Failover-timeout: 60000ms
Parallel-syncs: 1
Auth: (same password as cluster)
```

## Memory Budget

### BEAST
- Redis Cluster: 6 nodes Ã— 2GB = 12GB max
- System overhead: ~4GB
- Available RAM: Likely 32-64GB (plenty of headroom)

### NAS
- Sentinel 1: ~50MB
- Sentinel 2: ~50MB
- Sentinel 3: ~50MB
- **Total**: ~150MB
- **OS + buffers**: ~400MB
- **Reserved buffer**: 1GB
- **Available**: 1.8GB total â†’ **650MB free** âœ…

## Failure Modes

### Master Failure
- **Detection**: Sentinels ping timeout (5s)
- **Action**: Promote replica to master
- **Downtime**: < 10s
- **Data loss**: None (if AOF enabled)

### Replica Failure
- **Detection**: Master notices replication lag
- **Action**: Master continues alone
- **Impact**: Reduced redundancy until replica returns

### BEAST Complete Failure
- **Impact**: All data nodes offline
- **Recovery**: Restore from NAS backups
- **Downtime**: Manual intervention required
- **Data loss**: Since last backup (1 hour max)

### NAS Complete Failure
- **Impact**: No monitoring or failover
- **Cluster**: Continues operating normally
- **Risk**: No auto-failover if master fails
- **Backups**: Temporarily unavailable

### Network Partition
- **Split brain protection**: Quorum prevents dual masters
- **Sentinel**: Requires 2/3 to promote replica
- **Cluster**: Majority partition remains writable

## Scaling Strategy

### Current (Phase 1)
- 3 masters on BEAST
- 3 replicas on BEAST
- 3 sentinels on NAS

### Phase 2 (Add DELL)
- Keep 3 masters on BEAST
- Move replicas to DELL (3 Ã— 12GB VRAM nodes)
- Add 3 sentinels on DELL
- **Total**: 6 sentinels, better distribution

### Phase 3 (More compute nodes)
- Add more masters (resharding required)
- Add replicas on new nodes
- Sentinel quorum increases with more nodes

## Monitoring

### Health Checks
```bash
# Cluster health
redis-cli -c -p 7000 -a "$PASSWORD" CLUSTER INFO

# Node status
redis-cli -c -p 7000 -a "$PASSWORD" CLUSTER NODES

# Sentinel status
redis-cli -p 26379 SENTINEL masters

# Replication lag
redis-cli -p 7000 -a "$PASSWORD" INFO replication
```

### Metrics to Watch
- Cluster state: `cluster_state:ok`
- Slots coverage: all 16384 slots assigned
- Replication lag: < 1s ideal
- Memory usage: < 80% of maxmemory
- Connected clients: varies by load

## Backup Schedule

### Automated (to implement)
```bash
# Hourly backup (retain 24)
0 * * * * /mnt/build/MCP/hive-mind/scripts/backup-redis.sh hourly

# Daily backup (retain 7)
0 2 * * * /mnt/build/MCP/hive-mind/scripts/backup-redis.sh daily

# Weekly backup (retain 4)
0 3 * * 0 /mnt/build/MCP/hive-mind/scripts/backup-redis.sh weekly
```

### Manual Backup
```bash
# Trigger BGSAVE on all masters
for port in 7000 7001 7002; do
  redis-cli -p $port -a "$PASSWORD" BGSAVE
done

# Copy to NAS
cp -r /mnt/build/redis-cluster/node-*/data/dump.rdb \
  /mnt/nas-moar/redis-backups/$(date +%Y%m%d-%H%M%S)/
```

## Security Considerations

- âœ… Password auth on all nodes
- âœ… Protected mode disabled (trusted network)
- âš ï¸ No TLS (local network only)
- âš ï¸ Firewall: Ensure ports 7000-7005, 26379-26381 restricted to local network

## Performance Expectations

### Latency
- **Cluster node**: < 1ms (in-memory)
- **Network RTT**: < 3ms (BEAST â†” NAS)
- **Failover**: < 10s

### Throughput
- **Per node**: ~100K ops/sec
- **Cluster total**: ~300K ops/sec (3 masters)
- **Network**: 1Gbps = ~125MB/s max

---

**Status**: Cluster deployed, Sentinel ready to deploy
**Next**: Build static Redis binary for NAS Sentinel
